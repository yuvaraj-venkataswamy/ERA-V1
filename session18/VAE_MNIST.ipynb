{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89210,"status":"ok","timestamp":1696512752219,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"A5YXxedlCMdV","outputId":"f7d3e2ba-7191-4b12-ff74-6a0cf5152de3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/S18\n"]}],"source":["# mounting google drive folder\n","from google.colab import drive\n","drive.mount('/content/drive')\n","BASE_DIR='/content/drive/My Drive/S18'\n","%cd $BASE_DIR"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7281,"status":"ok","timestamp":1696512000391,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"DjE5ctkI_dYA","outputId":"f0639b8e-4926-4b5a-ae00-1fd77de44764"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00\u003c00:00, 100258778.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00\u003c00:00, 42563490.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00\u003c00:00, 26498581.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00\u003c00:00, 5151576.19it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# prerequisites\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","\n","bs = 100\n","# MNIST Dataset\n","train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n","test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6437,"status":"ok","timestamp":1696512026048,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"q0gzwSWa_ily"},"outputs":[],"source":["class VAE(nn.Module):\n","    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n","        super(VAE, self).__init__()\n","\n","        # encoder part\n","        self.fc1 = nn.Linear(x_dim, h_dim1)\n","        self.fc2 = nn.Linear(h_dim1, h_dim2)\n","        self.fc31 = nn.Linear(h_dim2, z_dim)\n","        self.fc32 = nn.Linear(h_dim2, z_dim)\n","        # decoder part\n","        self.fc4 = nn.Linear(z_dim, h_dim2)\n","        self.fc5 = nn.Linear(h_dim2, h_dim1)\n","        self.fc6 = nn.Linear(h_dim1, x_dim)\n","\n","    def encoder(self, x):\n","        h = F.relu(self.fc1(x))\n","        h = F.relu(self.fc2(h))\n","        return self.fc31(h), self.fc32(h) # mu, log_var\n","\n","    def sampling(self, mu, log_var):\n","        std = torch.exp(0.5*log_var)\n","        eps = torch.randn_like(std)\n","        return eps.mul(std).add_(mu) # return z sample\n","\n","    def decoder(self, z):\n","        h = F.relu(self.fc4(z))\n","        h = F.relu(self.fc5(h))\n","        return F.sigmoid(self.fc6(h))\n","\n","    def forward(self, x):\n","        mu, log_var = self.encoder(x.view(-1, 784))\n","        z = self.sampling(mu, log_var)\n","        return self.decoder(z), mu, log_var\n","\n","# build model\n","vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n","if torch.cuda.is_available():\n","    vae.cuda()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1696512037560,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"gn8CTh8D_ioc","outputId":"001b419a-dffa-4bd1-a61e-65e72f1c4d52"},"outputs":[{"data":{"text/plain":["VAE(\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc31): Linear(in_features=256, out_features=2, bias=True)\n","  (fc32): Linear(in_features=256, out_features=2, bias=True)\n","  (fc4): Linear(in_features=2, out_features=256, bias=True)\n","  (fc5): Linear(in_features=256, out_features=512, bias=True)\n","  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["vae"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1696512050436,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"aa-xZdwA_irI"},"outputs":[],"source":["optimizer = optim.Adam(vae.parameters())\n","# return reconstruction error + KL divergence losses\n","def loss_function(recon_x, x, mu, log_var):\n","    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","    return BCE + KLD"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1696512067562,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"N3pEZkTx_iup"},"outputs":[],"source":["def train(epoch):\n","    vae.train()\n","    train_loss = 0\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","        data = data.cuda()\n","        optimizer.zero_grad()\n","\n","        recon_batch, mu, log_var = vae(data)\n","        loss = loss_function(recon_batch, data, mu, log_var)\n","\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n","    print('====\u003e Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":614,"status":"ok","timestamp":1696512086493,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"GNZ0RYLx__2I"},"outputs":[],"source":["def test():\n","    vae.eval()\n","    test_loss= 0\n","    with torch.no_grad():\n","        for data, _ in test_loader:\n","            data = data.cuda()\n","            recon, mu, log_var = vae(data)\n","\n","            # sum up batch loss\n","            test_loss += loss_function(recon, data, mu, log_var).item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('====\u003e Test set loss: {:.4f}'.format(test_loss))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450660,"status":"ok","timestamp":1696512549647,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"Rp1P-I0v___g","outputId":"642e03e4-77db-4a69-aaf8-abc50c2e78eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 544.195898\n","Train Epoch: 1 [10000/60000 (17%)]\tLoss: 194.384844\n","Train Epoch: 1 [20000/60000 (33%)]\tLoss: 177.211504\n","Train Epoch: 1 [30000/60000 (50%)]\tLoss: 162.616445\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 166.537148\n","Train Epoch: 1 [50000/60000 (83%)]\tLoss: 164.836797\n","====\u003e Epoch: 1 Average loss: 179.0400\n","====\u003e Test set loss: 162.0697\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 157.701455\n","Train Epoch: 2 [10000/60000 (17%)]\tLoss: 165.279727\n","Train Epoch: 2 [20000/60000 (33%)]\tLoss: 147.623867\n","Train Epoch: 2 [30000/60000 (50%)]\tLoss: 157.643135\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 149.173486\n","Train Epoch: 2 [50000/60000 (83%)]\tLoss: 156.284443\n","====\u003e Epoch: 2 Average loss: 157.6774\n","====\u003e Test set loss: 154.6477\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 148.318457\n","Train Epoch: 3 [10000/60000 (17%)]\tLoss: 152.446377\n","Train Epoch: 3 [20000/60000 (33%)]\tLoss: 156.264336\n","Train Epoch: 3 [30000/60000 (50%)]\tLoss: 157.552383\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 150.946738\n","Train Epoch: 3 [50000/60000 (83%)]\tLoss: 152.400010\n","====\u003e Epoch: 3 Average loss: 152.3500\n","====\u003e Test set loss: 150.8948\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 141.571611\n","Train Epoch: 4 [10000/60000 (17%)]\tLoss: 149.781074\n","Train Epoch: 4 [20000/60000 (33%)]\tLoss: 149.309814\n","Train Epoch: 4 [30000/60000 (50%)]\tLoss: 149.713213\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 152.538633\n","Train Epoch: 4 [50000/60000 (83%)]\tLoss: 150.843115\n","====\u003e Epoch: 4 Average loss: 149.4915\n","====\u003e Test set loss: 148.3789\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 145.315830\n","Train Epoch: 5 [10000/60000 (17%)]\tLoss: 155.302197\n","Train Epoch: 5 [20000/60000 (33%)]\tLoss: 139.438008\n","Train Epoch: 5 [30000/60000 (50%)]\tLoss: 152.012344\n","Train Epoch: 5 [40000/60000 (67%)]\tLoss: 155.677744\n","Train Epoch: 5 [50000/60000 (83%)]\tLoss: 150.982295\n","====\u003e Epoch: 5 Average loss: 147.4198\n","====\u003e Test set loss: 146.8082\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 156.173857\n","Train Epoch: 6 [10000/60000 (17%)]\tLoss: 141.788584\n","Train Epoch: 6 [20000/60000 (33%)]\tLoss: 139.624766\n","Train Epoch: 6 [30000/60000 (50%)]\tLoss: 149.576621\n","Train Epoch: 6 [40000/60000 (67%)]\tLoss: 150.045078\n","Train Epoch: 6 [50000/60000 (83%)]\tLoss: 142.550010\n","====\u003e Epoch: 6 Average loss: 145.8324\n","====\u003e Test set loss: 145.5493\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 148.542002\n","Train Epoch: 7 [10000/60000 (17%)]\tLoss: 143.269785\n","Train Epoch: 7 [20000/60000 (33%)]\tLoss: 151.355820\n","Train Epoch: 7 [30000/60000 (50%)]\tLoss: 151.127715\n","Train Epoch: 7 [40000/60000 (67%)]\tLoss: 142.015967\n","Train Epoch: 7 [50000/60000 (83%)]\tLoss: 139.744453\n","====\u003e Epoch: 7 Average loss: 144.5298\n","====\u003e Test set loss: 144.3759\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 145.773037\n","Train Epoch: 8 [10000/60000 (17%)]\tLoss: 140.977480\n","Train Epoch: 8 [20000/60000 (33%)]\tLoss: 145.326602\n","Train Epoch: 8 [30000/60000 (50%)]\tLoss: 143.814316\n","Train Epoch: 8 [40000/60000 (67%)]\tLoss: 148.636914\n","Train Epoch: 8 [50000/60000 (83%)]\tLoss: 143.155645\n","====\u003e Epoch: 8 Average loss: 143.7877\n","====\u003e Test set loss: 143.7794\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 149.068076\n","Train Epoch: 9 [10000/60000 (17%)]\tLoss: 138.577109\n","Train Epoch: 9 [20000/60000 (33%)]\tLoss: 140.857559\n","Train Epoch: 9 [30000/60000 (50%)]\tLoss: 148.708008\n","Train Epoch: 9 [40000/60000 (67%)]\tLoss: 136.739551\n","Train Epoch: 9 [50000/60000 (83%)]\tLoss: 138.654258\n","====\u003e Epoch: 9 Average loss: 142.8416\n","====\u003e Test set loss: 143.3373\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 151.096973\n","Train Epoch: 10 [10000/60000 (17%)]\tLoss: 139.394502\n","Train Epoch: 10 [20000/60000 (33%)]\tLoss: 139.342012\n","Train Epoch: 10 [30000/60000 (50%)]\tLoss: 138.044004\n","Train Epoch: 10 [40000/60000 (67%)]\tLoss: 134.311445\n","Train Epoch: 10 [50000/60000 (83%)]\tLoss: 135.252617\n","====\u003e Epoch: 10 Average loss: 142.2526\n","====\u003e Test set loss: 142.5053\n","Train Epoch: 11 [0/60000 (0%)]\tLoss: 140.724014\n","Train Epoch: 11 [10000/60000 (17%)]\tLoss: 140.106611\n","Train Epoch: 11 [20000/60000 (33%)]\tLoss: 139.559482\n","Train Epoch: 11 [30000/60000 (50%)]\tLoss: 140.034521\n","Train Epoch: 11 [40000/60000 (67%)]\tLoss: 141.001816\n","Train Epoch: 11 [50000/60000 (83%)]\tLoss: 141.779824\n","====\u003e Epoch: 11 Average loss: 141.4509\n","====\u003e Test set loss: 141.8595\n","Train Epoch: 12 [0/60000 (0%)]\tLoss: 144.611367\n","Train Epoch: 12 [10000/60000 (17%)]\tLoss: 141.820547\n","Train Epoch: 12 [20000/60000 (33%)]\tLoss: 142.598955\n","Train Epoch: 12 [30000/60000 (50%)]\tLoss: 142.099736\n","Train Epoch: 12 [40000/60000 (67%)]\tLoss: 139.003633\n","Train Epoch: 12 [50000/60000 (83%)]\tLoss: 139.467842\n","====\u003e Epoch: 12 Average loss: 140.9416\n","====\u003e Test set loss: 141.2715\n","Train Epoch: 13 [0/60000 (0%)]\tLoss: 146.212773\n","Train Epoch: 13 [10000/60000 (17%)]\tLoss: 137.412861\n","Train Epoch: 13 [20000/60000 (33%)]\tLoss: 135.042695\n","Train Epoch: 13 [30000/60000 (50%)]\tLoss: 141.275918\n","Train Epoch: 13 [40000/60000 (67%)]\tLoss: 142.917236\n","Train Epoch: 13 [50000/60000 (83%)]\tLoss: 134.253828\n","====\u003e Epoch: 13 Average loss: 140.4071\n","====\u003e Test set loss: 140.8013\n","Train Epoch: 14 [0/60000 (0%)]\tLoss: 139.026387\n","Train Epoch: 14 [10000/60000 (17%)]\tLoss: 139.727344\n","Train Epoch: 14 [20000/60000 (33%)]\tLoss: 140.622168\n","Train Epoch: 14 [30000/60000 (50%)]\tLoss: 143.879961\n","Train Epoch: 14 [40000/60000 (67%)]\tLoss: 134.709629\n","Train Epoch: 14 [50000/60000 (83%)]\tLoss: 144.099570\n","====\u003e Epoch: 14 Average loss: 140.1082\n","====\u003e Test set loss: 140.6423\n","Train Epoch: 15 [0/60000 (0%)]\tLoss: 139.433535\n","Train Epoch: 15 [10000/60000 (17%)]\tLoss: 144.638584\n","Train Epoch: 15 [20000/60000 (33%)]\tLoss: 137.710596\n","Train Epoch: 15 [30000/60000 (50%)]\tLoss: 136.468926\n","Train Epoch: 15 [40000/60000 (67%)]\tLoss: 138.947930\n","Train Epoch: 15 [50000/60000 (83%)]\tLoss: 138.054883\n","====\u003e Epoch: 15 Average loss: 139.7725\n","====\u003e Test set loss: 140.4568\n","Train Epoch: 16 [0/60000 (0%)]\tLoss: 138.758018\n","Train Epoch: 16 [10000/60000 (17%)]\tLoss: 140.878730\n","Train Epoch: 16 [20000/60000 (33%)]\tLoss: 131.529785\n","Train Epoch: 16 [30000/60000 (50%)]\tLoss: 140.952129\n","Train Epoch: 16 [40000/60000 (67%)]\tLoss: 142.071133\n","Train Epoch: 16 [50000/60000 (83%)]\tLoss: 138.350830\n","====\u003e Epoch: 16 Average loss: 139.2847\n","====\u003e Test set loss: 140.0116\n","Train Epoch: 17 [0/60000 (0%)]\tLoss: 139.680430\n","Train Epoch: 17 [10000/60000 (17%)]\tLoss: 143.861055\n","Train Epoch: 17 [20000/60000 (33%)]\tLoss: 139.842998\n","Train Epoch: 17 [30000/60000 (50%)]\tLoss: 142.289570\n","Train Epoch: 17 [40000/60000 (67%)]\tLoss: 131.191660\n","Train Epoch: 17 [50000/60000 (83%)]\tLoss: 139.587871\n","====\u003e Epoch: 17 Average loss: 138.9750\n","====\u003e Test set loss: 140.3093\n","Train Epoch: 18 [0/60000 (0%)]\tLoss: 138.978525\n","Train Epoch: 18 [10000/60000 (17%)]\tLoss: 138.747891\n","Train Epoch: 18 [20000/60000 (33%)]\tLoss: 138.831543\n","Train Epoch: 18 [30000/60000 (50%)]\tLoss: 138.876973\n","Train Epoch: 18 [40000/60000 (67%)]\tLoss: 132.175684\n","Train Epoch: 18 [50000/60000 (83%)]\tLoss: 140.040186\n","====\u003e Epoch: 18 Average loss: 138.9589\n","====\u003e Test set loss: 139.7524\n","Train Epoch: 19 [0/60000 (0%)]\tLoss: 140.362637\n","Train Epoch: 19 [10000/60000 (17%)]\tLoss: 140.845293\n","Train Epoch: 19 [20000/60000 (33%)]\tLoss: 133.227002\n","Train Epoch: 19 [30000/60000 (50%)]\tLoss: 137.683838\n","Train Epoch: 19 [40000/60000 (67%)]\tLoss: 140.249375\n","Train Epoch: 19 [50000/60000 (83%)]\tLoss: 138.550234\n","====\u003e Epoch: 19 Average loss: 138.3948\n","====\u003e Test set loss: 139.7877\n","Train Epoch: 20 [0/60000 (0%)]\tLoss: 133.878418\n","Train Epoch: 20 [10000/60000 (17%)]\tLoss: 137.904922\n","Train Epoch: 20 [20000/60000 (33%)]\tLoss: 143.305244\n","Train Epoch: 20 [30000/60000 (50%)]\tLoss: 149.542686\n","Train Epoch: 20 [40000/60000 (67%)]\tLoss: 137.446016\n","Train Epoch: 20 [50000/60000 (83%)]\tLoss: 136.664375\n","====\u003e Epoch: 20 Average loss: 138.4861\n","====\u003e Test set loss: 139.4070\n","Train Epoch: 21 [0/60000 (0%)]\tLoss: 137.809600\n","Train Epoch: 21 [10000/60000 (17%)]\tLoss: 137.175439\n","Train Epoch: 21 [20000/60000 (33%)]\tLoss: 133.654482\n","Train Epoch: 21 [30000/60000 (50%)]\tLoss: 142.910264\n","Train Epoch: 21 [40000/60000 (67%)]\tLoss: 130.378691\n","Train Epoch: 21 [50000/60000 (83%)]\tLoss: 143.343418\n","====\u003e Epoch: 21 Average loss: 138.1523\n","====\u003e Test set loss: 139.5133\n","Train Epoch: 22 [0/60000 (0%)]\tLoss: 138.366094\n","Train Epoch: 22 [10000/60000 (17%)]\tLoss: 130.030029\n","Train Epoch: 22 [20000/60000 (33%)]\tLoss: 132.681035\n","Train Epoch: 22 [30000/60000 (50%)]\tLoss: 139.839639\n","Train Epoch: 22 [40000/60000 (67%)]\tLoss: 129.342607\n","Train Epoch: 22 [50000/60000 (83%)]\tLoss: 132.971914\n","====\u003e Epoch: 22 Average loss: 138.2829\n","====\u003e Test set loss: 139.4610\n","Train Epoch: 23 [0/60000 (0%)]\tLoss: 133.030273\n","Train Epoch: 23 [10000/60000 (17%)]\tLoss: 140.805117\n","Train Epoch: 23 [20000/60000 (33%)]\tLoss: 139.902754\n","Train Epoch: 23 [30000/60000 (50%)]\tLoss: 142.306777\n","Train Epoch: 23 [40000/60000 (67%)]\tLoss: 143.736816\n","Train Epoch: 23 [50000/60000 (83%)]\tLoss: 143.635488\n","====\u003e Epoch: 23 Average loss: 138.1156\n","====\u003e Test set loss: 138.9570\n","Train Epoch: 24 [0/60000 (0%)]\tLoss: 132.256279\n","Train Epoch: 24 [10000/60000 (17%)]\tLoss: 133.571250\n","Train Epoch: 24 [20000/60000 (33%)]\tLoss: 137.419189\n","Train Epoch: 24 [30000/60000 (50%)]\tLoss: 136.967461\n","Train Epoch: 24 [40000/60000 (67%)]\tLoss: 144.700801\n","Train Epoch: 24 [50000/60000 (83%)]\tLoss: 135.225791\n","====\u003e Epoch: 24 Average loss: 137.8434\n","====\u003e Test set loss: 139.0169\n","Train Epoch: 25 [0/60000 (0%)]\tLoss: 134.463887\n","Train Epoch: 25 [10000/60000 (17%)]\tLoss: 145.240537\n","Train Epoch: 25 [20000/60000 (33%)]\tLoss: 136.227070\n","Train Epoch: 25 [30000/60000 (50%)]\tLoss: 136.455156\n","Train Epoch: 25 [40000/60000 (67%)]\tLoss: 132.068311\n","Train Epoch: 25 [50000/60000 (83%)]\tLoss: 138.016797\n","====\u003e Epoch: 25 Average loss: 137.2735\n","====\u003e Test set loss: 139.1683\n","Train Epoch: 26 [0/60000 (0%)]\tLoss: 131.095039\n","Train Epoch: 26 [10000/60000 (17%)]\tLoss: 146.151953\n","Train Epoch: 26 [20000/60000 (33%)]\tLoss: 133.326992\n","Train Epoch: 26 [30000/60000 (50%)]\tLoss: 139.731504\n","Train Epoch: 26 [40000/60000 (67%)]\tLoss: 132.530039\n","Train Epoch: 26 [50000/60000 (83%)]\tLoss: 143.957783\n","====\u003e Epoch: 26 Average loss: 137.1663\n","====\u003e Test set loss: 139.2930\n","Train Epoch: 27 [0/60000 (0%)]\tLoss: 129.377588\n","Train Epoch: 27 [10000/60000 (17%)]\tLoss: 137.527314\n","Train Epoch: 27 [20000/60000 (33%)]\tLoss: 136.300996\n","Train Epoch: 27 [30000/60000 (50%)]\tLoss: 140.147051\n","Train Epoch: 27 [40000/60000 (67%)]\tLoss: 133.810352\n","Train Epoch: 27 [50000/60000 (83%)]\tLoss: 143.131563\n","====\u003e Epoch: 27 Average loss: 137.2149\n","====\u003e Test set loss: 138.7071\n","Train Epoch: 28 [0/60000 (0%)]\tLoss: 145.735186\n","Train Epoch: 28 [10000/60000 (17%)]\tLoss: 136.223535\n","Train Epoch: 28 [20000/60000 (33%)]\tLoss: 137.180635\n","Train Epoch: 28 [30000/60000 (50%)]\tLoss: 138.030146\n","Train Epoch: 28 [40000/60000 (67%)]\tLoss: 135.017549\n","Train Epoch: 28 [50000/60000 (83%)]\tLoss: 141.297920\n","====\u003e Epoch: 28 Average loss: 136.9639\n","====\u003e Test set loss: 138.6124\n","Train Epoch: 29 [0/60000 (0%)]\tLoss: 132.240479\n","Train Epoch: 29 [10000/60000 (17%)]\tLoss: 135.598770\n","Train Epoch: 29 [20000/60000 (33%)]\tLoss: 139.783271\n","Train Epoch: 29 [30000/60000 (50%)]\tLoss: 131.642754\n","Train Epoch: 29 [40000/60000 (67%)]\tLoss: 133.906172\n","Train Epoch: 29 [50000/60000 (83%)]\tLoss: 136.632910\n","====\u003e Epoch: 29 Average loss: 136.8265\n","====\u003e Test set loss: 138.5209\n","Train Epoch: 30 [0/60000 (0%)]\tLoss: 132.769072\n","Train Epoch: 30 [10000/60000 (17%)]\tLoss: 133.405576\n","Train Epoch: 30 [20000/60000 (33%)]\tLoss: 141.252344\n","Train Epoch: 30 [30000/60000 (50%)]\tLoss: 139.013242\n","Train Epoch: 30 [40000/60000 (67%)]\tLoss: 134.879053\n","Train Epoch: 30 [50000/60000 (83%)]\tLoss: 131.748311\n","====\u003e Epoch: 30 Average loss: 136.6272\n","====\u003e Test set loss: 137.8738\n","Train Epoch: 31 [0/60000 (0%)]\tLoss: 134.776064\n","Train Epoch: 31 [10000/60000 (17%)]\tLoss: 138.250107\n","Train Epoch: 31 [20000/60000 (33%)]\tLoss: 141.796211\n","Train Epoch: 31 [30000/60000 (50%)]\tLoss: 134.142461\n","Train Epoch: 31 [40000/60000 (67%)]\tLoss: 137.750254\n","Train Epoch: 31 [50000/60000 (83%)]\tLoss: 142.500527\n","====\u003e Epoch: 31 Average loss: 136.6009\n","====\u003e Test set loss: 138.7438\n","Train Epoch: 32 [0/60000 (0%)]\tLoss: 141.156484\n","Train Epoch: 32 [10000/60000 (17%)]\tLoss: 139.329736\n","Train Epoch: 32 [20000/60000 (33%)]\tLoss: 135.902402\n","Train Epoch: 32 [30000/60000 (50%)]\tLoss: 138.782852\n","Train Epoch: 32 [40000/60000 (67%)]\tLoss: 140.884893\n","Train Epoch: 32 [50000/60000 (83%)]\tLoss: 136.295371\n","====\u003e Epoch: 32 Average loss: 136.5410\n","====\u003e Test set loss: 138.2008\n","Train Epoch: 33 [0/60000 (0%)]\tLoss: 136.958838\n","Train Epoch: 33 [10000/60000 (17%)]\tLoss: 139.214736\n","Train Epoch: 33 [20000/60000 (33%)]\tLoss: 143.574385\n","Train Epoch: 33 [30000/60000 (50%)]\tLoss: 138.172168\n","Train Epoch: 33 [40000/60000 (67%)]\tLoss: 134.621270\n","Train Epoch: 33 [50000/60000 (83%)]\tLoss: 136.593418\n","====\u003e Epoch: 33 Average loss: 136.4975\n","====\u003e Test set loss: 138.1587\n","Train Epoch: 34 [0/60000 (0%)]\tLoss: 138.185469\n","Train Epoch: 34 [10000/60000 (17%)]\tLoss: 130.082061\n","Train Epoch: 34 [20000/60000 (33%)]\tLoss: 136.596299\n","Train Epoch: 34 [30000/60000 (50%)]\tLoss: 136.767041\n","Train Epoch: 34 [40000/60000 (67%)]\tLoss: 138.055957\n","Train Epoch: 34 [50000/60000 (83%)]\tLoss: 136.394775\n","====\u003e Epoch: 34 Average loss: 136.4653\n","====\u003e Test set loss: 138.3585\n","Train Epoch: 35 [0/60000 (0%)]\tLoss: 132.224121\n","Train Epoch: 35 [10000/60000 (17%)]\tLoss: 142.943262\n","Train Epoch: 35 [20000/60000 (33%)]\tLoss: 127.743154\n","Train Epoch: 35 [30000/60000 (50%)]\tLoss: 138.941660\n","Train Epoch: 35 [40000/60000 (67%)]\tLoss: 129.918574\n","Train Epoch: 35 [50000/60000 (83%)]\tLoss: 137.887627\n","====\u003e Epoch: 35 Average loss: 135.9049\n","====\u003e Test set loss: 138.4904\n","Train Epoch: 36 [0/60000 (0%)]\tLoss: 135.749961\n","Train Epoch: 36 [10000/60000 (17%)]\tLoss: 139.008662\n","Train Epoch: 36 [20000/60000 (33%)]\tLoss: 132.823848\n","Train Epoch: 36 [30000/60000 (50%)]\tLoss: 141.762373\n","Train Epoch: 36 [40000/60000 (67%)]\tLoss: 138.630937\n","Train Epoch: 36 [50000/60000 (83%)]\tLoss: 135.844834\n","====\u003e Epoch: 36 Average loss: 135.9458\n","====\u003e Test set loss: 138.3565\n","Train Epoch: 37 [0/60000 (0%)]\tLoss: 130.922061\n","Train Epoch: 37 [10000/60000 (17%)]\tLoss: 140.733516\n","Train Epoch: 37 [20000/60000 (33%)]\tLoss: 133.737910\n","Train Epoch: 37 [30000/60000 (50%)]\tLoss: 136.544678\n","Train Epoch: 37 [40000/60000 (67%)]\tLoss: 130.099619\n","Train Epoch: 37 [50000/60000 (83%)]\tLoss: 132.348877\n","====\u003e Epoch: 37 Average loss: 135.9985\n","====\u003e Test set loss: 137.8849\n","Train Epoch: 38 [0/60000 (0%)]\tLoss: 138.092051\n","Train Epoch: 38 [10000/60000 (17%)]\tLoss: 136.084482\n","Train Epoch: 38 [20000/60000 (33%)]\tLoss: 127.628066\n","Train Epoch: 38 [30000/60000 (50%)]\tLoss: 134.326836\n","Train Epoch: 38 [40000/60000 (67%)]\tLoss: 141.000664\n","Train Epoch: 38 [50000/60000 (83%)]\tLoss: 138.838994\n","====\u003e Epoch: 38 Average loss: 135.8726\n","====\u003e Test set loss: 138.0964\n","Train Epoch: 39 [0/60000 (0%)]\tLoss: 136.680215\n","Train Epoch: 39 [10000/60000 (17%)]\tLoss: 130.148027\n","Train Epoch: 39 [20000/60000 (33%)]\tLoss: 140.763721\n","Train Epoch: 39 [30000/60000 (50%)]\tLoss: 140.074502\n","Train Epoch: 39 [40000/60000 (67%)]\tLoss: 130.617822\n","Train Epoch: 39 [50000/60000 (83%)]\tLoss: 135.427793\n","====\u003e Epoch: 39 Average loss: 135.7360\n","====\u003e Test set loss: 137.8611\n","Train Epoch: 40 [0/60000 (0%)]\tLoss: 137.677363\n","Train Epoch: 40 [10000/60000 (17%)]\tLoss: 136.718408\n","Train Epoch: 40 [20000/60000 (33%)]\tLoss: 132.918203\n","Train Epoch: 40 [30000/60000 (50%)]\tLoss: 137.945498\n","Train Epoch: 40 [40000/60000 (67%)]\tLoss: 140.784092\n","Train Epoch: 40 [50000/60000 (83%)]\tLoss: 130.619043\n","====\u003e Epoch: 40 Average loss: 135.4918\n","====\u003e Test set loss: 138.0266\n","Train Epoch: 41 [0/60000 (0%)]\tLoss: 134.045674\n","Train Epoch: 41 [10000/60000 (17%)]\tLoss: 137.065400\n","Train Epoch: 41 [20000/60000 (33%)]\tLoss: 151.669551\n","Train Epoch: 41 [30000/60000 (50%)]\tLoss: 134.313018\n","Train Epoch: 41 [40000/60000 (67%)]\tLoss: 136.163242\n","Train Epoch: 41 [50000/60000 (83%)]\tLoss: 140.065410\n","====\u003e Epoch: 41 Average loss: 135.5230\n","====\u003e Test set loss: 138.4332\n","Train Epoch: 42 [0/60000 (0%)]\tLoss: 128.456084\n","Train Epoch: 42 [10000/60000 (17%)]\tLoss: 139.679902\n","Train Epoch: 42 [20000/60000 (33%)]\tLoss: 133.596592\n","Train Epoch: 42 [30000/60000 (50%)]\tLoss: 133.994512\n","Train Epoch: 42 [40000/60000 (67%)]\tLoss: 136.305166\n","Train Epoch: 42 [50000/60000 (83%)]\tLoss: 142.499248\n","====\u003e Epoch: 42 Average loss: 135.4873\n","====\u003e Test set loss: 137.8245\n","Train Epoch: 43 [0/60000 (0%)]\tLoss: 127.448760\n","Train Epoch: 43 [10000/60000 (17%)]\tLoss: 127.454580\n","Train Epoch: 43 [20000/60000 (33%)]\tLoss: 136.453994\n","Train Epoch: 43 [30000/60000 (50%)]\tLoss: 135.598750\n","Train Epoch: 43 [40000/60000 (67%)]\tLoss: 140.230000\n","Train Epoch: 43 [50000/60000 (83%)]\tLoss: 129.843467\n","====\u003e Epoch: 43 Average loss: 135.5810\n","====\u003e Test set loss: 138.4572\n","Train Epoch: 44 [0/60000 (0%)]\tLoss: 128.699639\n","Train Epoch: 44 [10000/60000 (17%)]\tLoss: 144.033838\n","Train Epoch: 44 [20000/60000 (33%)]\tLoss: 130.192461\n","Train Epoch: 44 [30000/60000 (50%)]\tLoss: 133.781816\n","Train Epoch: 44 [40000/60000 (67%)]\tLoss: 129.969482\n","Train Epoch: 44 [50000/60000 (83%)]\tLoss: 135.692939\n","====\u003e Epoch: 44 Average loss: 135.2271\n","====\u003e Test set loss: 137.4178\n","Train Epoch: 45 [0/60000 (0%)]\tLoss: 135.100205\n","Train Epoch: 45 [10000/60000 (17%)]\tLoss: 133.103359\n","Train Epoch: 45 [20000/60000 (33%)]\tLoss: 131.981953\n","Train Epoch: 45 [30000/60000 (50%)]\tLoss: 130.370879\n","Train Epoch: 45 [40000/60000 (67%)]\tLoss: 143.846582\n","Train Epoch: 45 [50000/60000 (83%)]\tLoss: 134.081699\n","====\u003e Epoch: 45 Average loss: 135.0124\n","====\u003e Test set loss: 137.2049\n","Train Epoch: 46 [0/60000 (0%)]\tLoss: 136.891729\n","Train Epoch: 46 [10000/60000 (17%)]\tLoss: 135.252627\n","Train Epoch: 46 [20000/60000 (33%)]\tLoss: 130.670322\n","Train Epoch: 46 [30000/60000 (50%)]\tLoss: 139.275059\n","Train Epoch: 46 [40000/60000 (67%)]\tLoss: 134.273516\n","Train Epoch: 46 [50000/60000 (83%)]\tLoss: 137.020908\n","====\u003e Epoch: 46 Average loss: 135.0299\n","====\u003e Test set loss: 137.7413\n","Train Epoch: 47 [0/60000 (0%)]\tLoss: 133.402422\n","Train Epoch: 47 [10000/60000 (17%)]\tLoss: 132.917969\n","Train Epoch: 47 [20000/60000 (33%)]\tLoss: 137.300859\n","Train Epoch: 47 [30000/60000 (50%)]\tLoss: 141.409004\n","Train Epoch: 47 [40000/60000 (67%)]\tLoss: 134.546074\n","Train Epoch: 47 [50000/60000 (83%)]\tLoss: 134.192275\n","====\u003e Epoch: 47 Average loss: 135.1026\n","====\u003e Test set loss: 137.6792\n","Train Epoch: 48 [0/60000 (0%)]\tLoss: 141.351992\n","Train Epoch: 48 [10000/60000 (17%)]\tLoss: 135.481914\n","Train Epoch: 48 [20000/60000 (33%)]\tLoss: 141.578516\n","Train Epoch: 48 [30000/60000 (50%)]\tLoss: 130.685527\n","Train Epoch: 48 [40000/60000 (67%)]\tLoss: 144.405059\n","Train Epoch: 48 [50000/60000 (83%)]\tLoss: 138.571221\n","====\u003e Epoch: 48 Average loss: 134.9793\n","====\u003e Test set loss: 137.6100\n","Train Epoch: 49 [0/60000 (0%)]\tLoss: 138.832295\n","Train Epoch: 49 [10000/60000 (17%)]\tLoss: 134.086475\n","Train Epoch: 49 [20000/60000 (33%)]\tLoss: 130.903193\n","Train Epoch: 49 [30000/60000 (50%)]\tLoss: 136.403691\n","Train Epoch: 49 [40000/60000 (67%)]\tLoss: 130.657119\n","Train Epoch: 49 [50000/60000 (83%)]\tLoss: 130.195684\n","====\u003e Epoch: 49 Average loss: 135.2809\n","====\u003e Test set loss: 139.0948\n","Train Epoch: 50 [0/60000 (0%)]\tLoss: 139.063437\n","Train Epoch: 50 [10000/60000 (17%)]\tLoss: 140.035596\n","Train Epoch: 50 [20000/60000 (33%)]\tLoss: 138.343301\n","Train Epoch: 50 [30000/60000 (50%)]\tLoss: 135.820137\n","Train Epoch: 50 [40000/60000 (67%)]\tLoss: 135.444385\n","Train Epoch: 50 [50000/60000 (83%)]\tLoss: 136.917236\n","====\u003e Epoch: 50 Average loss: 135.1667\n","====\u003e Test set loss: 137.9537\n"]}],"source":["for epoch in range(1, 51):\n","    train(epoch)\n","    test()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1696512884809,"user":{"displayName":"Atharv Yuvaraj","userId":"06637266434318105218"},"user_tz":-330},"id":"PRvjm0_kAADH"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-15-6e75d2face24\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./samples/MNISTsample_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'decoder'"]}],"source":["with torch.no_grad():\n","    z = torch.randn(64, 2).cuda()\n","    sample = vae.decoder(z).cuda()\n","\n","    save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVflCM1pDVnv"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOw8y9BLpGVxKstqj9ZpUU6","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}